---
layout: post
title: Refactoring to Data Driven Tests
description: "I don't like writing tests. They are repetitive and boring. But I found a way to write them less and have more tested."
modified: 2019-08-20
tags: [dotnet, testing, NUnit, XUnit, DDT, craft, data driven testing, tests]
image:
 feature: data/2019-08-20-refactoring-to-data-driven-tests/logo.jpg
---

The [previous post](/refactoring-to-data-driven-tests/) was meant to be an encouragement and a warmup to data driven testing. This post describes why I actually love them.
Those are the tips, trics, and good (for me) practicess that moved them from "nice idea" to ["I want it all! And I want it now!"](https://www.youtube.com/watch?v=hFDcoX7s6rE&feature=youtu.be&t=6)

# Data is the king

Anyone who is a bit interested in machine learning will know lines like: "data is the king", "data is the new oil" etc. For me this applies in the same way to tests. Having tests is not valuable. 
Having tests with right test data is the value. Let me explain. [Previously ](/refactoring-to-data-driven-tests/) I wrote that I don't like writing tests. 
I uphold this statement. But let me be more precise. Preparing a test for a class is somewat interesting. 
It can be one of two:

- It is a verfication of the quality of code you produced. 
- Or can be the verification of the skill in hacking using mocks, stubs and fakes you poses.

Pick one, but I propose the first option.

The part that drains my mental energy the most is writing test cases and tests data. This was the reason why I tried most auto testing approaches in the .net eco system with the biggest hopes for [Pex](https://www.microsoft.com/en-us/research/publication/pex-white-box-test-generation-for-net/)
But, as most Microsoft products, it died. And for a good reason because it approached producting testing data from the wrong angle.
It analyzed the code and found edge cases. Sounds reasonable - this is how we write tests. 
But is it how we should write tests? Writing tests this way is just duplicating the conditions from `if`s, `switch`es etc.

I am not saying that such tests aren't necessary. They are very usefull, but only initially to do the first verification. After passing a breaking point of code complexity of invested time they are a waste of time. 
Time spend vs. value produced is just to low.

# How to get test data

So where to get better test data? That is simple. From the users. In users I include all things and people using this piace of code. 

## Messages

Some architectures are just perfect for gathering data on what failed. One of such is message based architectures. If developed properly, almost all the data a function needs is in the message. If a message handler fails just 